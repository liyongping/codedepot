{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re, sys\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CtlFile:\n",
    "    ctlFileName = \"\"\n",
    "    lineStartPos = 1\n",
    "    fieldDic = dict()\n",
    "    posDic = dict()\n",
    "\n",
    "    def __init__(self, fileName):\n",
    "        self.ctlFileName = fileName\n",
    "        self.parse()\n",
    "    def parse(self):\n",
    "        fieldPosition = 0\n",
    "        ctlre = r\"FIELDS TERMINATED BY '\u0012'.\\((.*)\\)\"\n",
    "        isFirstField = True\n",
    "        text = file(self.ctlFileName).read()\n",
    "\n",
    "        ctlreobj = re.findall(ctlre, text, re.MULTILINE | re.DOTALL)\n",
    "        fieldsText = ctlreobj[0].lstrip().rstrip()\n",
    "\n",
    "        for field in fieldsText.split(','):\n",
    "            if isFirstField == True:\n",
    "                x = re.findall(\"position\\((\\d+)\\)\", field)\n",
    "                if len(x) > 0:\n",
    "                    self.lineStartPos = int(x[0])\n",
    "                isFirstField = False\n",
    "            fname = field.replace('\\t', ' ').lstrip().rstrip().split(' ')[0].lstrip().rstrip()\n",
    "            if fname.upper() not in ['PLAN_ID', 'LAST_UPDATE_LOGIN', 'LAST_UPDATE_DATE', 'CREATION_DATE', 'LOW_LEVEL_CODE', 'LAST_REPLAN_DATE']:\n",
    "                self.fieldDic[fname] = fieldPosition\n",
    "                self.posDic[fieldPosition + 1] = fname\n",
    "            fieldPosition = fieldPosition + 1\n",
    "            \n",
    "    def printMsg(self):\n",
    "        print self.fieldDic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insert', 'pegging_id', 'inventory_item_id', 'organization_id', 'sr_instance_id', 'demand_id', 'end_pegging_id', 'demand_quantity', 'transaction_id', 'supply_type', 'supply_quantity', 'allocated_quantity', 'prev_pegging_id', 'end_item_usage', 'supply_date', 'demand_date', 'disposition_id', 'status', 'updated', 'last_updated_by', 'created_by', 'project_id', 'task_id', 'unit_number', 'end_origination_type', 'reserved_qty', 'dummy1', 'dummy2', 'dummy3'] 29\n"
     ]
    }
   ],
   "source": [
    "def get_columns(ctl_file_name):\n",
    "    ctl_fp = CtlFile(ctl_file_name)\n",
    "    sorted_x = sorted(ctl_fp.fieldDic.items(), key=operator.itemgetter(1))\n",
    "    columns = map(lambda (k,v): k, sorted_x)\n",
    "    return columns\n",
    "\n",
    "fp_columns = get_columns(\"D:\\\\projects\\\\scripts_to_pbn\\\\test_case\\\\mbpoutput_good\\\\MSLD_FULL_PEGGING.ctl.x\");\n",
    "\n",
    "fp_columns = [\"insert\"]\n",
    "fp_columns += get_columns(\"D:\\\\projects\\\\scripts_to_pbn\\\\test_case\\\\mbpoutput_good\\\\MSLD_FULL_PEGGING.ctl.x\");\n",
    "fp_columns +=[\"dummy1\",\"dummy2\",\"dummy3\"]\n",
    "print fp_columns, len(fp_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_shema(schema_file_path):\n",
    "    schema = {}\n",
    "    print \"Load schema from: \" + schema_file_path\n",
    "    col = 0\n",
    "    with open(schema_file_path) as schema_file:\n",
    "        for line in schema_file:\n",
    "            col = line.strip().split()\n",
    "            if len(col) > 1:\n",
    "                try:\n",
    "                    row_num = int(col[0])\n",
    "                except:\n",
    "                    print 'ERROR: row_num ' + col[0] + ' is not an integer number'\n",
    "                    sys.exit(1)\n",
    "                schema[row_num] = col[len(col)-1]\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load schema from: D:\\projects\\scripts_to_pbn\\ColumnNames\\MSLD_FULL_PEGGING.dat\n",
      "Load schema from: D:\\projects\\scripts_to_pbn\\ColumnNames\\MSLD_SUPPLIES.dat\n",
      "Load schema from: D:\\projects\\scripts_to_pbn\\ColumnNames\\MSLD_DEMANDS.dat\n"
     ]
    }
   ],
   "source": [
    "data_delimiter = \"\\022\"\n",
    "cn_folder = \"ColumnNames\"\n",
    "#cn_path = os.path.join(\".\", cn_folder)\n",
    "cn_path = \"D:\\\\projects\\\\scripts_to_pbn\\\\ColumnNames\"\n",
    "full_pegging_shema_path = os.path.join(cn_path, \"MSLD_FULL_PEGGING.dat\")\n",
    "supplies_shema_path     = os.path.join(cn_path, \"MSLD_SUPPLIES.dat\")\n",
    "demands_shema_path      = os.path.join(cn_path, \"MSLD_DEMANDS.dat\")\n",
    "exceptions_shema_path   = os.path.join(cn_path, \"MSLD_EXCEPTION_DETAIL.dat\")\n",
    "\n",
    "#mbpoutput_path = os.path.join(\".\", \"mbpoutput\")\n",
    "mbpoutput_path = \"D:\\\\projects\\\\scripts_to_pbn\\\\test_case\\\\mbpoutput_bad\"\n",
    "#mbpoutput_path = \"D:\\\\bugs2\\\\25215185\\\\data21\\\\data21\\\\mbpoutput\"\n",
    "full_pegging_ff_path = os.path.join(mbpoutput_path, \"MSLD_FULL_PEGGING.dat\")\n",
    "supplies_ff_path     = os.path.join(mbpoutput_path, \"MSLD_SUPPLIES.dat\")\n",
    "demands_ff_path      = os.path.join(mbpoutput_path, \"MSLD_DEMANDS.dat\")\n",
    "exceptions_ff_path   = os.path.join(mbpoutput_path, \"MSLD_EXCEPTION_DETAIL.dat\")\n",
    "\n",
    "full_pegging_shema = load_shema(full_pegging_shema_path)\n",
    "supplies_shema = load_shema(supplies_shema_path)\n",
    "demands_shema = load_shema(demands_shema_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'dummy_long', 2: 'id', 3: 'item_id', 4: 'org_id', 5: 'sr_instance_id', 6: 'demand_id', 7: 'end_pegging_id', 8: 'demand_qty', 9: 'trans_id', 10: 'supply_type', 11: 'supply_qty', 12: 'alloc_qty', 13: 'prev_level_id', 14: 'end_usage', 15: 'supply_date', 16: 'demand_date', 17: 'disp_id', 18: 'dummy_long', 19: 'dummy_long', 20: 'user_id', 21: 'dummy_long', 22: 'project_id', 23: 'task_id', 24: 'unit_num', 25: 'end_orig_type', 26: 'reserved_qty', 27: 'orig_end_priority', 28: 'end_priority', 29: 'peg_loc'}\n"
     ]
    }
   ],
   "source": [
    "print full_pegging_shema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Common on-hand pegs to excess, but we created planned orders for that item\n",
    "def check_planned_order(check_onhand2excess):\n",
    "    df_supplies = pd.read_csv(supplies_ff_path, sep=data_delimiter, names=supplies_shema.values())\n",
    "    df_planned_order = df_supplies[(df_supplies.order_type == 5) & (df_supplies.firm_type == 2)]\n",
    "    if df_planned_order.item_id.count() > 0:\n",
    "        df_item_org_instance = df_planned_order[[\"item_id\", \"org_id\", \"sr_instance_id\"]].drop_duplicates()\n",
    "        results = check_onhand2excess.merge(df_item_org_instance, on=[\"item_id\", \"org_id\", \"sr_instance_id\"])\n",
    "        output = results[[\"item_id\", \"org_id\", \"sr_instance_id\",\"trans_id\", \"supply_qty\", \"alloc_qty\"]]\n",
    "        if output.item_id.count() > 0:\n",
    "            print \"Found: \" + str(output.item_id.count())\n",
    "            print output\n",
    "        else:\n",
    "            print \"DON'T find.\"\n",
    "\n",
    "def comm_oh_excess_pl_ord():\n",
    "    print \"Checking 'Common on-hand pegs to excess, but we created planned orders for that item'...\"\n",
    "    df_full_pegging = pd.read_csv(full_pegging_ff_path, sep=data_delimiter, names=full_pegging_shema.values())\n",
    "    check_onhand2excess = df_full_pegging[(df_full_pegging.supply_type == 18) & (df_full_pegging.demand_id == -1) & (df_full_pegging.project_id == -23453)]\n",
    "    if check_onhand2excess.item_id.count() > 0:\n",
    "        check_planned_order(check_onhand2excess)\n",
    "    else:\n",
    "        print \"DON'T find.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unmet demands\n",
    "def check_unmet_demands():\n",
    "    command_str = \"awk -F '\\022' '{if($2==67) {print $1, $2,$3,$4, $8,$11}}' \" + exceptions_ff_path + \" | wc -l\"\n",
    "    print \"Checking unmet demands with following commands: \"\n",
    "    print command_str\n",
    "    rt=os.popen(command_str)\n",
    "    output = rt.readlines();\n",
    "    if len(output) > 0:\n",
    "        print \"Found \" + str(output[0].strip()) + \" unmet demands!\"\n",
    "    else:\n",
    "        print \"Errors in checking unmet demands\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Supplies belonging to a certain project (PG1), were allocated to demands in of a different project/planning group (PG2). \n",
    "The reservation level on the plan is planning group.\n",
    "'''\n",
    "\n",
    "def check_cross_peg_across_pg():\n",
    "    print \"Checking cross pegging across planning group...\"\n",
    "    df_supplies = pd.read_csv(supplies_ff_path, sep=data_delimiter, names=supplies_shema.values())\n",
    "    df_full_pegging = pd.read_csv(full_pegging_ff_path, sep=data_delimiter, names=full_pegging_shema.values())\n",
    "    df_demands = pd.read_csv(demands_ff_path, sep=data_delimiter, names=demands_shema.values())\n",
    "    \n",
    "    join_output = df_full_pegging.merge(df_supplies, on=[\"item_id\", \"org_id\", \"sr_instance_id\", \"trans_id\"])\\\n",
    "               .merge(df_demands, on=[\"item_id\", \"org_id\", \"sr_instance_id\", \"demand_id\"])\n",
    "    checking_output = join_output[((join_output.planning_group_x == -23453) & # ms.planning_group IS NULL\n",
    "           (join_output.planning_group_y == -23453) &   # md.planning_group IS NULL\n",
    "           (join_output.project_id_y != -23453) &       # ms.project_id IS NOT NULL\n",
    "           (join_output.project_id != -23453) &         # md.project_id IS NOT NULL\n",
    "           (join_output.project_id_y != join_output.project_id))  # ms.project_id <> md.project_id\n",
    "            |\n",
    "            ((join_output.planning_group_y != -23453) &   # md.planning_group IS NOT NULL\n",
    "             (join_output.planning_group_x != -23453) &   # ms.planning_group IS NOT NULL     \n",
    "             (join_output.planning_group_x != join_output.planning_group_y) # ms.planning_group <> md.planning_group\n",
    "            )\n",
    "            |\n",
    "            ((join_output.planning_group_y == -23453) &   # md.planning_group IS NULL\n",
    "             (join_output.planning_group_x != -23453)     # ms.planning_group IS NOT NULL\n",
    "            )\n",
    "            |\n",
    "            ((join_output.project_id == -23453) &         # md.project_id IS NULL\n",
    "             (join_output.project_id_y != -23453)         # ms.project_id IS NOT NULL\n",
    "            )\n",
    "           ]\n",
    "    if checking_output.item_id.count() > 0:\n",
    "        print \"Found \" + str(checking_output.item_id.count()) + \" cross pegging records\"\n",
    "        '''print checking_output[[\"item_id\", \"org_id\", \"sr_instance_id\", \"trans_id\", \"supply_qty\",\\\n",
    "                               \"alloc_qty\",\"supply_type\",\"demand_id\", \"project_id_y\",\"planning_group_x\",\\\n",
    "                               \"project_id\", \"planning_group_y\"]]'''\n",
    "    else:\n",
    "        print \"DON'T find any cross pegging acorss planning group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 'Common on-hand pegs to excess, but we created planned orders for that item'...\n",
      "Found: 5746\n",
      "      item_id  org_id  sr_instance_id    trans_id  supply_qty  alloc_qty\n",
      "0       18071    1747               1  1755872159      4175.0     4142.0\n",
      "1        3678    1747               1  1755879435        19.0        1.0\n",
      "2        5677    1747               1  1755879936         2.0        2.0\n",
      "3        3438    1747               1  1755868560        45.0       24.0\n",
      "4        3448    1747               1  1755874813        25.0        6.0\n",
      "5       18068    1778               1  1755936447       246.0      148.0\n",
      "6       18071    1768               1  1755891126         3.0        3.0\n",
      "7       18113    1747               1  1755872157        13.0        6.0\n",
      "8       18115    1747               1  1755863959        88.0       66.0\n",
      "9       18115    1747               1  1755861376         9.0        9.0\n",
      "10       3117    1747               1  1755861739        32.0       19.0\n",
      "11       3371    1747               1  1755879439       230.0      139.0\n",
      "12       3685    1747               1  1755866507         4.0        1.0\n",
      "13       3685    1747               1  1755862799         3.0        3.0\n",
      "14       3436    1747               1  1755877065       268.0      175.0\n",
      "15      18073    1747               1  1755872231       579.0       84.0\n",
      "16      18073    1747               1  1755873922        12.0       12.0\n",
      "17      18101    1747               1  1755874816        22.0        1.0\n",
      "18      18101    1747               1  1755868557         2.0        2.0\n",
      "19     279977    1747               1  1755868568       219.0      214.0\n",
      "20       3678    1770               1  1755911531         6.0        6.0\n",
      "21       3438    1770               1  1755908684        21.0       21.0\n",
      "22      18068    3035               1  1755962931        59.0       59.0\n",
      "23      18071    1778               1  1755942101       149.0      146.0\n",
      "24       3438    1778               1  1755943216        14.0        2.0\n",
      "25       3438    1778               1  1755939229         1.0        1.0\n",
      "26       3448    1778               1  1755941818        11.0        2.0\n",
      "27       3371    1768               1  1755893554        11.0       11.0\n",
      "28     279977    1768               1  1755895895        14.0       12.0\n",
      "29      18117    1747               1  1755868565        95.0       73.0\n",
      "...       ...     ...             ...         ...         ...        ...\n",
      "5716   195942    6072               1  1755989942       285.0      285.0\n",
      "5717   280107    6072               1  1755990205        22.0       22.0\n",
      "5718   280111    6072               1  1755988818         4.0        4.0\n",
      "5719   280119    6072               1  1755988817        12.0       12.0\n",
      "5720   178876    6072               1  1755989842        15.0       15.0\n",
      "5721   209959    6072               1  1755990213         1.0        1.0\n",
      "5722   206950    6072               1  1755989429       209.0      209.0\n",
      "5723   207891    6072               1  1755990214         5.0        5.0\n",
      "5724     4474    7952               1  1755993339        47.0       29.0\n",
      "5725     4474    7952               1  1755992422         5.0        5.0\n",
      "5726     3465    7952               1  1755994439         1.0        1.0\n",
      "5727    18040    7952               1  1755994583        10.0       10.0\n",
      "5728     3490    7952               1  1755993446         2.0        2.0\n",
      "5729   195956    7952               1  1755993420        27.0       10.0\n",
      "5730    73889    7952               1  1755995712         1.0        1.0\n",
      "5731     6159    7952               1  1755993538        34.0       34.0\n",
      "5732     6215    7952               1  1755994569        15.0       15.0\n",
      "5733   292059    7952               1  1755995141        31.0       31.0\n",
      "5734   292059    7952               1  1755992277        37.0       37.0\n",
      "5735   178876    7952               1  1755993044       166.0      149.0\n",
      "5736   347510    7952               1  1755995219         3.0        3.0\n",
      "5737   273526    7952               1  1755994027         3.0        3.0\n",
      "5738    83970    7952               1  1755993454      1408.0     1391.0\n",
      "5739   278881    7952               1  1755993355         2.0        2.0\n",
      "5740    85868    7952               1  1755992306         1.0        1.0\n",
      "5741   275677    7952               1  1755994669        10.0       10.0\n",
      "5742     6163    8632               1  1755996497         5.0        5.0\n",
      "5743     6155    8632               1  1755996665         1.0        1.0\n",
      "5744   292059    8632               1  1755996918         2.0        2.0\n",
      "5745   178876    8632               1  1755997067        17.0       17.0\n",
      "\n",
      "[5746 rows x 6 columns]\n",
      "Checking unmet demands with following commands: \n",
      "awk -F '\u0012' '{if($2==67) {print $1, $2,$3,$4, $8,$11}}' D:\\projects\\scripts_to_pbn\\test_case\\mbpoutput_bad\\MSLD_EXCEPTION_DETAIL.dat | wc -l\n",
      "Found 0 unmet demands!\n",
      "Checking cross pegging across planning group...\n",
      "Found 22649 cross pegging records\n"
     ]
    }
   ],
   "source": [
    "comm_oh_excess_pl_ord()\n",
    "check_unmet_demands()\n",
    "check_cross_peg_across_pg()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
